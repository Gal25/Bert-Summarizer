{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-extractive-summarizer in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (0.10.1)\r\n",
      "Requirement already satisfied: spacy in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from bert-extractive-summarizer) (3.4.2)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from bert-extractive-summarizer) (1.1.3)\r\n",
      "Requirement already satisfied: transformers in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from bert-extractive-summarizer) (4.23.1)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from scikit-learn->bert-extractive-summarizer) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from scikit-learn->bert-extractive-summarizer) (3.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from scikit-learn->bert-extractive-summarizer) (1.23.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from scikit-learn->bert-extractive-summarizer) (1.9.3)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (0.10.1)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (1.10.2)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (2.0.8)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (3.3.0)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (1.0.3)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (1.0.9)\r\n",
      "Requirement already satisfied: jinja2 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (60.2.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (4.64.1)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (2.4.5)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (3.0.10)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (8.1.5)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (2.28.1)\r\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (0.4.2)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (3.0.8)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (2.0.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (21.3)\r\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from spacy->bert-extractive-summarizer) (0.6.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from transformers->bert-extractive-summarizer) (6.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from transformers->bert-extractive-summarizer) (0.13.1)\r\n",
      "Requirement already satisfied: filelock in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from transformers->bert-extractive-summarizer) (3.8.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from transformers->bert-extractive-summarizer) (2022.10.31)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from transformers->bert-extractive-summarizer) (0.10.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers->bert-extractive-summarizer) (4.4.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from packaging>=20.0->spacy->bert-extractive-summarizer) (3.0.9)\r\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from pathy>=0.3.5->spacy->bert-extractive-summarizer) (5.2.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2022.9.24)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->bert-extractive-summarizer) (0.7.9)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->bert-extractive-summarizer) (0.0.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/i030642/PycharmProjects/ICBC/venv/lib/python3.9/site-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.1)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/i030642/PycharmProjects/ICBC/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-extractive-summarizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'לפני שנים רבות חיה נערה צעירה בשם סינדרלה עם אמה ושתי אחיותיה החורגות.\\nסינדרלה המסכנה נאלצה לעבוד קשה כל היום כדי שאמה החורגת ואחיותיה החורגות האחרים יוכלו לנוח.\\nהיא הייתה זו שנאלצה להתעורר בכל בוקר כשעדיין חשוך וקר כדי להדליק את האש באח, היא זו שבישלה את כל הארוחות, הגישה אותם וגם ניקתה את הבית, הנערה המסכנה לא יכלה להישאר נקייה מכל עבודות הבית המתישות.\\n\\nבנוסף לכך, שתי אחיותיה החורגות צחקו ולעגו לה כל הזמן.\\nיום אחד, הגיעו חדשות גדולות לעיר. המלך והמלכה התכוונו לעשות נשף גדול מכיוון שהגיע הזמן שהנסיך ימצא כלה.\\nכל הנשים הצעירות במדינה הוזמנו  לנשף, הן התכוננו היטב לנשף, הסתרקו והכינו בגדים יפים כדי לזכות בליבו של הנסיך.\\nלסינדרלה כעת הייתה לה עבודה נוספת לעשות, היא נאלצה להכין שתי שמלות חדשות לגמרי עבור אחיותיה החורגות.\\n\"מהר יותר!\" צעקה אחות חורגת אחת.\\n\"את קוראת לזה שמלה?\" צרחה השניה\\nהאם החורגת צעדה אל החדר ואמרה \"את צריכה לעשות את השמלות יפות יותר\".\\n\"בסדר אבל..\" אמרה הנערה, \"מתי יהיה לי זמן להכין את השמלה שלי לנשף?\"\\n\"את?\" צעקה האם החורגת. \"מי אמר שאת הולכת לנשף?\"\\n\"איזו מצחיקה!\" אמרה אחות חורגת אחת.\\n\"תראי איך את נראית, למה את חושבת שהנסיך ירצה אותך בכלל?!\" הם הצביעו על סינדרלה וצחקו.\\nסינדרלה אמרה לעצמה, \"כשהם מסתכלים עליי, אולי הם רואים בלאגן, אבל אני לא כזאת, ואם הייתי יכולה, הייתי הולכת לנשף\".\\nעד מהרה הגיע הזמן של האם והאחיות החורגות לצאת לנשף הגדול.\\n\\nהכרכרה המשובחת שהזמינו הגיעה אל הדלת, האם והאחיות החורגות קפצו פנימה\\n\"ביי ביי\" סינדרלה. \"תהני בבית\" אמרו וצחקו.\\n\"אוי..\" אמרה סינדרלה בעצב. הכרכרה נסעה, היא אמרה בקול שקט, \"הלוואי שגם אני יכולתי ללכת לנשף!\"\\nואז – בום!\\nפתאום, מולה עמדה פיה.\\n\"קראת לי?\" אמרה הפיה.\\n\"מה?\" אמרה סינדרלה. \"מי את?\"\\n\"הפיה שלך, כמובן! אני יודעת מה את רוצה ובאתי להעניק לך את המתנה הזאת.\"\\n\"אבל…\" אמרה סינדרלה, \"המשאלה שלי היא בלתי אפשרית.\"\\n\"סלחי לי!\" אמרה הפיה \"איך לדעתך הופעתי פתאום?\"\\n\"כן.. באמת הגעת יש מאין\" אמרה סינדרלה.\\n\"אז תני לי להיות זאת שתגיד מה אפשרי או ומה לא!\"\\n\"טוב, אני חושבת שאת יודעת שגם אני רוצה ללכת לנשף.\" אמרה סינדרלה והשפילה מבט אל בגדיה המלוכלכים.\\n\"אבל תסתכלי עליי.\"\\n\"כן, את נראית קצת מבולגנת\" אמרה הפיה.\\n\"גם אם היה לי משהו נחמד ללבוש,\" אמרה הנערה, \"לא תהיה לי דרך להגיע לשם.\"\\n\"הכל אפשרי\" אמרה הפיה. הפיה הניפה את השרביט שלה על ראשה של סינדרלה.\\n\\nבאורח פלא סינדרלה הפכה לנקייה, היא הייתה לבושה בשמלה כחולה יפייפיה. שערה היה מסודר להפליא.\\n\"זה נפלא!\" אמרה סינדרלה.\\n\"מי אמר שסיימתי?\" אמרה הפיה, היא הניפה שוב את השרביט שלה ומיד נוצרה כרכרה יפה, עם נהג וארבעה סוסים לבנים.\\n\\n\"האם אני חולמת?\" אמרה סינדרלה והסתכלה סביבה.\\n\"זה אמיתי\" אמרה הפיה.. \"אבל יש דבר אחד שאת חייבת לדעת סינדרלה.\"\\n\"מה הדבר?\" שאלה סינדרלה בפליאה.\\n\"כל מה שאת רואה כאן יהיה עד חצות הלילה, בחצות, הכל ייגמר ויחזור להיות כמו שהיה קודם.\\n\"אז אני חייבת לעזוב את הנשף לפני חצות!\" אמרה סינדרלה.\\n\"בדיוק\" אמרה הפיה ופסעה לאחור. \"העבודה שלי הסתיימה.\" אמרה הפיה ונעלמה.\\nסינדרלה הביטה סביבה וחשבה: \"זה אמיתי?\" היא עמדה בשמלה משובחת, עם שיער יפה ומסודר עם נהג וארבעה סוסים לפניה, מחכים.\\n\"את נכנסת לכרכרה?\"  שאל לנהג.\\nהיא נכנסה לכרכרה והם יצאו לנשף.\\n\\nבזמן הנשף, הנסיך לא ידע מה לחשוב. \"למה יש לך את המבט העצוב הזה על הפנים שלך?\" שאלה המלכה את בנה. \"הבט סביבך! לא יכולת לבקש נערות טובות מאלה.\"\\n\"אני יודע, אמא\", אמר הנסיך, ובכל זאת הוא ידע שמשהו לא בסדר. הוא פגש רבות מהנשים הצעירות. אבל אחרי שאמר \"שלום\" לכל אחת הוא לא הרגיש את החיבור הנכון.\\n\"תראו!\" מישהו הצביע על דלת הכניסה. \"מי זאת?\"\\nכל הראשים הסתובבו. מי הייתה אותה עלמה מקסימה שירדה במדרגות? היא הרימה את ראשה גבוה ונראתה כאילו היא שייכת למקום. אבל אף אחד לא הכיר אותה.\\n\"יש בה משהו,\" אמר הנסיך לעצמו. \"אני אבקש ממנה לרקוד.\", הנסיך ניגש לסינדרלה.\\n\"האם נפגשנו בעבר?\" שאל הנסיך.\\n\"אני שמחה לפגוש אותך עכשיו\" אמרה סינדרלה במתיקות.\\n\"אני מרגיש כאילו אני מכיר אותך\" אמר הנסיך. \"אבל כמובן, זה בלתי אפשרי. אחרת הייתי זוכר.\"\\nהנסיך חש רטט בליבו. הוא וסינדרלה רקדו. כשהשיר נגמר, הם רקדו שוב. ואז הם רקדו שוב, ושוב. עד מהרה הבנות האחרות בנשף קינאו. \"למה הוא רוקד איתה כל הזמן?\" הם אמרו. \"כמה חצוף!\"\\nאבל כל מה שהנסיך ראה היה סינדרלה. הם צחקו ודיברו, והם רקדו עוד קצת. למעשה, הם רקדו כל כך הרבה זמן שסינדרלה לא ראתה את השעון.\\n\"דונג!\" צילצל השעון המרכזי בחוזקה.\\nסינדרלה הרימה את מבטה.\\n\\n\"דונג!\" צילצל שוב על השעון.\\nהיא הרימה שוב את מבטה. \"אוי!\" היא צעקה. \"השעה כבר כמעט חצות!\"\\n\"דונג!\" צלצל השעון שוב.\\n\"למה זה משנה?\" אמר הנסיך.\\n\"אני חייבת ללכת!\" אמרה סינדרלה.\\n\"אבל הרגע נפגשנו!\" אמר הנסיך. \"למה לעזוב עכשיו?\"\\n\"אני חייבת ללכת!\" אמרה סינדרלה ורצה אל המדרגות.\\n\"בבקשה, עצרי לרגע!\" אמר הנסיך.\\n\"אוי לא!\" היא אמרה כשנעל זכוכית אחת נפלה מרגלה על המדרגות. אבל סינדרלה המשיכה לרוץ.\\n\\n\"דונג!\" אחרון נשמע ולאחריו השעון היה שקט. השעה הייתה חצות בדיוק.\\nהנסיך כבר לא ראה את סינדרלה, הוא הרים את נעלי הזכוכית שלה וחזר לנשף.\\nהביט סביבו אך לא ראה את סינדרלה בשום מקום. \"זה כל מה שנשאר לי ממנה,\" הוא אמר והביט אל נעל הזכוכית בעצב.\\nהוא ראה שהנעל עשויה בצורה מיוחדת, כאילו מותאמת במיוחד לכף רגל שאין כמותה עוד. \"איפשהו קיימת נעל הזכוכית השנייה,\" הוא חשב. \"וכשאמצא את הנעל השנייה, אני אמצא גם את הנערה ואז אבקש ממנה להיות הכלה שלי!\"\\nמבקתה לבקתה, מבית לבית, הלך הנסיך והמשרתים שלו כדי למצוא למי שייכת הנעל, צעירה אחת אחרי השנייה ניסו להכניס את רגליהם לתוך נעל הזכוכית. אבל לאף אחד זה לא התאים, כך המשיך הנסיך לחפש את סינדרלה.\\nלבסוף הגיע הנסיך לביתה של סינדרלה.\\n\"הוא מגיע!\" קראה אחות חורגת אחת כשהסתכלה מהחלון.\\n\"בדלת!\" צרחה האחות החורגת השנייה.\\n\"מהר!\" צעקה האם החורגת. \"תתכוננו! אחת מכן חייבת להיות זו שתכניס את כף רגלה לנעל, לא משנה מה!\"\\nהנסיך דפק בדלת, האם החורגת באה בריצה ופתחה את הדלת. \"היכנס בבקשה!\" היא אמרה בנימוס לא אופייני, \"יש לי שתי בנות מקסימות שתוכל לראות.\"\\nהאחות החורגת הראשונה ניסתה להכניס את רגלה בנעל הזכוכית.\\nהיא ניסתה בכוח רב, אבל זה פשוט לא התאים.\\nהאחות החורגת השנייה ניסתה גם היא להכניס את רגלה פנימה בכל הכוח. אבל לא הייתה התאמה.\\n\"אין עוד נשים צעירות בבית?\" שאל הנסיך.\\n\"אף אחת\" אמרה האם החורגת.\\n\"אז אני חייב ללכת,\" אמר הנסיך.\\n\"אולי בכל זאת יש עוד אחת\" אמרה סינדרלה ונכנסה לחדר בהפתעה.\\n\"חשבתי שאמרת שאין כאן עוד נשים צעירות\" אמר הנסיך בכעס לאימה החורגת.\\n\"אף אחת חשובה..\" אמרה האם החורגת בלחישה.\\n\"בואי הנה\" אמר הנסיך.\\n\\nסינדרלה ניגשה אליו, הנסיך כרע ברך וניסה להכניס נעל הזכוכית לרגלה..\\n\"זה מתאים בצורה מושלמת!\" אמר הנסיך באושר, ואז, מהכיס שלה סינדרלה הוציאה משהו. זאת הייתה נעל הזכוכית השנייה!\\n\"ידעתי!\" הוא בכה. \"את האחת!\"\\n\"מה?\" צעקה אחות חורגת אחת.\\n\"לא היא!\" צרחה האחות החורגת השנייה.\\n\"זה לא יכול להיות!\" צעקה האם החורגת.\\nאבל זה היה מאוחר מידי. הנסיך ידע שסינדרלה היא האחת. הוא הביט בעיניה. הוא לא ראה את ההזנחה בשיערה או את הלכלוך על פניה.\\n\"מצאתי אותך!\" הוא אמר בלחש.\\n\"ואני מצאתי אותך\" אמרה סינדרלה.\\nוכך נישאו סינדרלה והנסיך, והם חיו באושר ועושר עד עצם היום הזה.\\n\\n\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=open('sinderela.txt','r').read()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer\n",
    "model = Summarizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "לפני שנים רבות חיה נערה צעירה בשם סינדרלה עם אמה ושתי אחיותיה החורגות. יום אחד, הגיעו חדשות גדולות לעיר. \"בסדר אבל..\" אמרה הנערה, \"מתי יהיה לי זמן להכין את השמלה שלי לנשף?\" הכרכרה המשובחת שהזמינו הגיעה אל הדלת, האם והאחיות החורגות קפצו פנימה\n",
      "\"ביי ביי\" סינדרלה. \" הכרכרה נסעה, היא אמרה בקול שקט, \"הלוואי שגם אני יכולתי ללכת לנשף!\" \"אז תני לי להיות זאת שתגיד מה אפשרי או ומה לא!\" אמרה סינדרלה והסתכלה סביבה. \"אז אני חייבת לעזוב את הנשף לפני חצות!\" היא עמדה בשמלה משובחת, עם שיער יפה ומסודר עם נהג וארבעה סוסים לפניה, מחכים. מישהו הצביע על דלת הכניסה. \" מי הייתה אותה עלמה מקסימה שירדה במדרגות? \"אני שמחה לפגוש אותך עכשיו\" אמרה סינדרלה במתיקות. למה הוא רוקד איתה כל הזמן?\" למעשה, הם רקדו כל כך הרבה זמן שסינדרלה לא ראתה את השעון. היא אמרה כשנעל זכוכית אחת נפלה מרגלה על המדרגות. צרחה האחות החורגת השנייה. אחת מכן חייבת להיות זו שתכניס את כף רגלה לנעל, לא משנה מה!\" הנסיך דפק בדלת, האם החורגת באה בריצה ופתחה את הדלת. \" האחות החורגת השנייה ניסתה גם היא להכניס את רגלה פנימה בכל הכוח. \"אין עוד נשים צעירות בבית?\" \"אף אחת חשובה..\" אמרה האם החורגת בלחישה.\n"
     ]
    }
   ],
   "source": [
    "result = model(data, min_length=20)\n",
    "summary = \"\".join(result)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Chrysler Building, the famous art deco New York skyscraper, will be sold for a small fraction of its previous sales price.\n",
      "The deal, first reported by The Real Deal, was for $150 million, according to a source familiar with the deal.\n",
      "Mubadala, an Abu Dhabi investment fund, purchased 90% of the building for $800 million in 2008.\n",
      "Real estate firm Tishman Speyer had owned the other 10%.\n",
      "The buyer is RFR Holding, a New York real estate company.\n",
      "Officials with Tishman and RFR did not immediately respond to a request for comments.\n",
      "It's unclear when the deal will close.\n",
      "The building sold fairly quickly after being publicly placed on the market only two months ago.\n",
      "The sale was handled by CBRE Group.\n",
      "The incentive to sell the building at such a huge loss was due to the soaring rent the owners pay to Cooper Union, a New York college, for the land under the building.\n",
      "The rent is rising from $7.75 million last year to $32.5 million this year to $41 million in 2028.\n",
      "Meantime, rents in the building itself are not rising nearly that fast.\n",
      "While the building is an iconic landmark in the New York skyline, it is competing against newer office towers with large floor-to-ceiling windows and all the modern amenities.\n",
      "Still the building is among the best known in the city, even to people who have never been to New York.\n",
      "It is famous for its triangle-shaped, vaulted windows worked into the stylized crown, along with its distinctive eagle gargoyles near the top.\n",
      "It has been featured prominently in many films, including Men in Black 3, Spider-Man, Armageddon, Two Weeks Notice and Independence Day.\n",
      "The previous sale took place just before the 2008 financial meltdown led to a plunge in real estate prices.\n",
      "Still there have been a number of high profile skyscrapers purchased for top dollar in recent years, including the Waldorf Astoria hotel, which Chinese firm Anbang Insurance purchased in 2016 for nearly $2 billion, and the Willis Tower in Chicago, which was formerly known as Sears Tower, once the world's tallest.\n",
      "Blackstone Group (BX) bought it for $1.3 billion 2015.\n",
      "The Chrysler Building was the headquarters of the American automaker until 1953, but it was named for and owned by Chrysler chief Walter Chrysler, not the company itself.\n",
      "Walter Chrysler had set out to build the tallest building in the world, a competition at that time with another Manhattan skyscraper under construction at 40 Wall Street at the south end of Manhattan. He kept secret the plans for the spire that would grace the top of the building, building it inside the structure and out of view of the public until 40 Wall Street was complete.\n",
      "Once the competitor could rise no higher, the spire of the Chrysler building was raised into view, giving it the title.\n",
      "\n",
      "Number of words in text file : 475\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "data=open('Chrysler.txt','r').read()\n",
    "print(data)\n",
    "words = data.split()\n",
    "print('Number of words in text file :', len(words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Chrysler Building, the famous art deco New York skyscraper, will be sold for a small fraction of its previous sales price. The deal, first reported by The Real Deal, was for $150 million, according to a source familiar with the deal. The buyer is RFR Holding, a New York real estate company. The building sold fairly quickly after being publicly placed on the market only two months ago. The incentive to sell the building at such a huge loss was due to the soaring rent the owners pay to Cooper Union, a New York college, for the land under the building.\n"
     ]
    }
   ],
   "source": [
    "result = model(data, min_length=20)\n",
    "summary = \"\".join(result)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Chrysler Building, the famous art deco New York skyscraper, will be sold for a small fraction of its previous sales price. The deal, first reported by The Real Deal, was for $150 million, according to a source familiar with the deal. The building sold fairly quickly after being publicly placed on the market only two months ago. The incentive to sell the building at such a huge loss was due to the soaring rent the owners pay to Cooper Union, a New York college, for the land under the building.\n"
     ]
    }
   ],
   "source": [
    "result = model(data, num_sentences=4)\n",
    "summary = \"\".join(result)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Chrysler Building, the famous art deco New York skyscraper, will be sold for a small fraction of its previous sales price. Real estate firm Tishman Speyer had owned the other 10%. The building sold fairly quickly after being publicly placed on the market only two months ago. The previous sale took place just before the 2008 financial meltdown led to a plunge in real estate prices. He kept secret the plans for the spire that would grace the top of the building, building it inside the structure and out of view of the public until 40 Wall Street was complete.\n"
     ]
    }
   ],
   "source": [
    "result = model(data, ratio=0.2)\n",
    "summary = \"\".join(result)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in text file : 2418\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "data=open('big.txt','r').read()\n",
    "words = data.split()\n",
    "print('Number of words in text file :', len(words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "\"The Adventures of Lone Wolf Scientific\"\n",
      "------------------------------------------\n",
      "An electronically syndicated series that\n",
      "follows the exploits of two of the\n",
      "computer industry's bona fide eccentrics. The programmer shuffling behind him, his arms full of\n",
      "boxes stuffed with fur dice, \"Honk If You Want Complete\n",
      "Schematics\" bumper-stickers, a plaster bust of John F.\n",
      "Kennedy, and all the other effluvium from their former\n",
      "office, didn't reply. BAS was the one most responsible for the bomb that\n",
      "had embarrassed him in front of half of the Pentagon's\n",
      "weapons shopaholics. How he had gotten himself into\n",
      "this mess with such a loonball he would never know.\n"
     ]
    }
   ],
   "source": [
    "result = model(data, num_sentences=4)\n",
    "summary = \"\".join(result)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "\"The Adventures of Lone Wolf Scientific\"\n",
      "------------------------------------------\n",
      "An electronically syndicated series that\n",
      "follows the exploits of two of the\n",
      "computer industry's bona fide eccentrics. The programmer shuffling behind him, his arms full of\n",
      "boxes stuffed with fur dice, \"Honk If You Want Complete\n",
      "Schematics\" bumper-stickers, a plaster bust of John F.\n",
      "Kennedy, and all the other effluvium from their former\n",
      "office, didn't reply. BAS wanted to reply that no, he had not told\n",
      "him, nor was he surprised that the mischievous S-max had\n",
      "been the subject of a congressional investigation, but he\n",
      "was too sad to answer. As the computer\n",
      "builder steered the satellite dish-topped van down the steep\n",
      "garage ramp with daredevilish swerves, he reflected on what\n",
      "they should do with the rest of their lives. How he had gotten himself into\n",
      "this mess with such a loonball he would never know. S-max continued, \"We could go on a lecture tour.\" S-max rattled on, \"We could hire ourselves out as\n",
      "consultants.\" S-max dreamed\n",
      "about someday having a credit line big enough to wage\n",
      "hostile takeovers of bloated computer manufacturers with\n",
      "nothing but an American Express card. \"I would like to share a secret about my inner self,\"\n",
      "he said, zig-zagging the van from one lane into another on\n",
      "the freeway with a kamikaze abruptness that caused the tires\n",
      "to squeel, horns to honk, and the satellite dish on top the\n",
      "van to creak and shiver. \"This is something that must be said, something that\n",
      "must be said now before our business plans go any further.\"\n"
     ]
    }
   ],
   "source": [
    "result = model(data, ratio=0.1)\n",
    "summary = \"\".join(result)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Summarizer in module summarizer.bert object:\n",
      "\n",
      "class Summarizer(BertSummarizer)\n",
      " |  Summarizer(model: str = 'bert-large-uncased', custom_model: transformers.modeling_utils.PreTrainedModel = None, custom_tokenizer: transformers.tokenization_utils.PreTrainedTokenizer = None, hidden: Union[List[int], int] = -2, reduce_option: str = 'mean', sentence_handler: summarizer.text_processors.sentence_handler.SentenceHandler = <summarizer.text_processors.sentence_handler.SentenceHandler object at 0x157e38fa0>, random_state: int = 12345, hidden_concat: bool = False, gpu_id: int = 0)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Summarizer\n",
      " |      BertSummarizer\n",
      " |      summarizer.summary_processor.SummaryProcessor\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model: str = 'bert-large-uncased', custom_model: transformers.modeling_utils.PreTrainedModel = None, custom_tokenizer: transformers.tokenization_utils.PreTrainedTokenizer = None, hidden: Union[List[int], int] = -2, reduce_option: str = 'mean', sentence_handler: summarizer.text_processors.sentence_handler.SentenceHandler = <summarizer.text_processors.sentence_handler.SentenceHandler object at 0x157e38fa0>, random_state: int = 12345, hidden_concat: bool = False, gpu_id: int = 0)\n",
      " |      This is the main Bert Summarizer class.\n",
      " |      \n",
      " |      :param model: This parameter is associated with the inherit string parameters from the transformers library.\n",
      " |      :param custom_model: If you have a pre-trained model, you can add the model class here.\n",
      " |      :param custom_tokenizer: If you have a custom tokenizer, you can add the tokenizer here.\n",
      " |      :param hidden: This signifies which layer of the BERT model you would like to use as embeddings.\n",
      " |      :param reduce_option: Given the output of the bert model, this param determines how you want to reduce results.\n",
      " |      :param random_state: The random state to reproduce summarizations.\n",
      " |      :param hidden_concat: Whether or not to concat multiple hidden layers.\n",
      " |      :param gpu_id: GPU device index if CUDA is available.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from summarizer.summary_processor.SummaryProcessor:\n",
      " |  \n",
      " |  __call__(self, body: str, ratio: float = 0.2, min_length: int = 40, max_length: int = 600, use_first: bool = True, algorithm: str = 'kmeans', num_sentences: int = None, return_as_list: bool = False) -> str\n",
      " |      (utility that wraps around the run function)\n",
      " |      Preprocesses the sentences, runs the clusters to find the centroids, then combines the sentences.\n",
      " |      \n",
      " |      :param body: The raw string body to process.\n",
      " |      :param ratio: Ratio of sentences to use.\n",
      " |      :param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
      " |      :param max_length: Maximum length of sentence candidates to utilize for the summary.\n",
      " |      :param use_first: Whether or not to use the first sentence.\n",
      " |      :param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
      " |      :param num_sentences: Number of sentences to use (overrides ratio).\n",
      " |      :param return_as_list: Whether or not to return sentences as list.\n",
      " |      :return: A summary sentence.\n",
      " |  \n",
      " |  calculate_elbow(self, body: str, algorithm: str = 'kmeans', min_length: int = 40, max_length: int = 600, k_max: int = None) -> List[float]\n",
      " |      Calculates elbow across the clusters.\n",
      " |      \n",
      " |      :param body: The input body to summarize.\n",
      " |      :param algorithm: The algorithm to use for clustering.\n",
      " |      :param min_length: The min length to use.\n",
      " |      :param max_length: The max length to use.\n",
      " |      :param k_max: The maximum number of clusters to search.\n",
      " |      :return: List of elbow inertia values.\n",
      " |  \n",
      " |  calculate_optimal_k(self, body: str, algorithm: str = 'kmeans', min_length: int = 40, max_length: int = 600, k_max: int = None) -> int\n",
      " |      Calculates the optimal Elbow K.\n",
      " |      \n",
      " |      :param body: The input body to summarize.\n",
      " |      :param algorithm: The algorithm to use for clustering.\n",
      " |      :param min_length: The min length to use.\n",
      " |      :param max_length: The max length to use.\n",
      " |      :param k_max: The maximum number of clusters to search.\n",
      " |      :return: The optimal k value as an int.\n",
      " |  \n",
      " |  cluster_runner(self, sentences: List[str], ratio: float = 0.2, algorithm: str = 'kmeans', use_first: bool = True, num_sentences: int = 3) -> Tuple[List[str], numpy.ndarray]\n",
      " |      Runs the cluster algorithm based on the hidden state. Returns both the embeddings and sentences.\n",
      " |      \n",
      " |      :param sentences: Content list of sentences.\n",
      " |      :param ratio: The ratio to use for clustering.\n",
      " |      :param algorithm: Type of algorithm to use for clustering.\n",
      " |      :param use_first: Return the first sentence in the output (helpful for news stories, etc).\n",
      " |      :param num_sentences: Number of sentences to use for summarization.\n",
      " |      :return: A tuple of summarized sentences and embeddings\n",
      " |  \n",
      " |  run(self, body: str, ratio: float = 0.2, min_length: int = 40, max_length: int = 600, use_first: bool = True, algorithm: str = 'kmeans', num_sentences: int = None, return_as_list: bool = False) -> Union[List, str]\n",
      " |      Preprocesses the sentences, runs the clusters to find the centroids, then combines the sentences.\n",
      " |      \n",
      " |      :param body: The raw string body to process\n",
      " |      :param ratio: Ratio of sentences to use\n",
      " |      :param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
      " |      :param max_length: Maximum length of sentence candidates to utilize for the summary\n",
      " |      :param use_first: Whether or not to use the first sentence\n",
      " |      :param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
      " |      :param num_sentences: Number of sentences to use (overrides ratio).\n",
      " |      :param return_as_list: Whether or not to return sentences as list.\n",
      " |      :return: A summary sentence\n",
      " |  \n",
      " |  run_embeddings(self, body: str, ratio: float = 0.2, min_length: int = 40, max_length: int = 600, use_first: bool = True, algorithm: str = 'kmeans', num_sentences: int = None, aggregate: str = None) -> Optional[numpy.ndarray]\n",
      " |      Preprocesses the sentences, runs the clusters to find the centroids, then combines the embeddings.\n",
      " |      \n",
      " |      :param body: The raw string body to process\n",
      " |      :param ratio: Ratio of sentences to use\n",
      " |      :param min_length: Minimum length of sentence candidates to utilize for the summary.\n",
      " |      :param max_length: Maximum length of sentence candidates to utilize for the summary\n",
      " |      :param use_first: Whether or not to use the first sentence\n",
      " |      :param algorithm: Which clustering algorithm to use. (kmeans, gmm)\n",
      " |      :param num_sentences: Number of sentences to use. Overrides ratio.\n",
      " |      :param aggregate: One of mean, median, max, min. Applied on zero axis\n",
      " |      :return: A summary embedding\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from summarizer.summary_processor.SummaryProcessor:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "summarizer.bert.Summarizer"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(model)\n",
    "type(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['finalized_model.sav']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model from disk\n",
    "# loaded_model = joblib.load('finalized_model.sav')\n",
    "#save model to disk\n",
    "import joblib\n",
    "joblib.dump(model, 'finalized_model.sav')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}